{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification\n",
    "\n",
    "Classification is the practice of bucketizing  (or categorizing) items based on common characteristics, and is an important principle of machine learning. For example, a robust spam email detection system should accurately catch and filter out which emails are spam, while letting ham (non-spam emails) through to the inbox.\n",
    "\n",
    "For the examples following along in this book, the question for this chapter is, \n",
    "\n",
    "    \"Can a machine distinguish between flower species based on images?\" \n",
    "\n",
    "We will use two datasets where measurements of flower morphology are recorded along with the species for several specimens.\n",
    "\n",
    "The **Iris dataset** is a classic dataset from the 1930s; it is one of the first modern\n",
    "examples of statistical classification.\n",
    "\n",
    "The dataset is a collection of morphological measurements of several Iris flowers. These measurements will enable us to distinguish multiple species of the flowers. Today, species are identified by their DNA fingerprints, but in the 1930s, DNA's role in genetics had not yet been discovered.\n",
    "\n",
    "The following four attributes (**features**) of each plant were measured, giving the dataset four features in total:\n",
    "    - sepal length\n",
    "    - sepal width\n",
    "    - petal length\n",
    "    - petal width\n",
    " \n",
    "The supervised learning, or classification problem we want to solve is, \n",
    "\n",
    "    \"Given these examples, if we see a new flower out in the field, \n",
    "    could we make a good prediction about its species from its measurements?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# This code based on supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert and Luis Pedro Coelho\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "import milksets.iris\n",
    "import milksets.seeds\n",
    "\n",
    "def save_as_tsv(fname, module):\n",
    "    features, labels = module.load()\n",
    "    nlabels = [module.label_names[ell] for ell in labels]\n",
    "    with open(fname, 'w') as ofile:\n",
    "        for f, n in zip(features, nlabels):\n",
    "            ofile.write(\"\\t\".join(map(str, f)))\n",
    "            ofile.write(\"\\n\")\n",
    "            \n",
    "#save_as_tsv('iris.tsv', milksets.iris)\n",
    "#save_as_tsv('seeds.tsv', milksets.seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Classification Model\n",
    "### Iris Speciation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Iris species\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "features = data.data\n",
    "feature_names = data.feature_names\n",
    "target = data.target\n",
    "target_names = data.target_names\n",
    "\n",
    "# Create 6 subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
    "pairs = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "\n",
    "# Create distinct markers for each species of Iris\n",
    "color_markers = [\n",
    "    ('r', '>'),\n",
    "    ('g', 'o'),\n",
    "    ('b', 'x')\n",
    "    ]\n",
    "\n",
    "for i, (p0, p1) in enumerate(pairs):\n",
    "    ax = axes.flat[i]\n",
    "    \n",
    "    for t in range(3):\n",
    "        c, marker = color_markers[t]\n",
    "        ax.scatter(features[target == t, p0], features[\n",
    "            target == t, p1], marker=marker, c=c)\n",
    "    ax.set_xlabel(feature_names[p0])\n",
    "    ax.set_ylabel(feature_names[p1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.tight_layout()\n",
    "fig.savefig('figure1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure1.png\" />\n",
    "\n",
    " - Red Triangles indicate Iris setosa\n",
    " - Blue Crosses indicate Iris Versicolor\n",
    " - Green Circles indicare Iris Virginica\n",
    "\n",
    "We can see from the above plots that petal length separates Iris setosa from the other species by a wide margin, so we can use code to figure out a good cutoff point.\n",
    "\n",
    "### Building a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of setosa: 1.9.\n",
      "Minimum of others: 3.0.\n"
     ]
    }
   ],
   "source": [
    "# Create an array of string using NumPy indexing\n",
    "labels = target_names[target]\n",
    "\n",
    "# Petal length is the feature as postion 2\n",
    "plength = features[:, 2]\n",
    "\n",
    "is_setosa = (labels == 'setosa')\n",
    "\n",
    "# Build the boundary\n",
    "max_setosa = plength[is_setosa].max()\n",
    "min_non_setosa = plength[~is_setosa].min()\n",
    "print('Maximum of setosa: {0}.'.format(max_setosa))\n",
    "print('Minimum of others: {0}.'.format(min_non_setosa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this simple model shows is that any Iris from these three species with a petal length smaller than 2 is an Iris Setosa. If an Iris has a petal length longer than 2, it can be assumed to be one of the other two types with a high level of confidence. In this case, we used eye shot to be able to verify this divide. Next, we'll use machine learning.\n",
    "\n",
    "    We run a loop over all possible features and thresholds to see which one results in better accuracy. \n",
    "    Accuracy is simply the fraction of examples that the model classifies correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ~ is the boolean negation operator\n",
    "features = features[~is_setosa]\n",
    "labels = labels[~is_setosa]\n",
    "# Build a new target variable, is_virigina\n",
    "is_virginica = (labels == 'virginica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names, target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll createa handful of funtions that can be resued to help fit our model to data, as well as predict its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    \n",
    "    # Apply learned model\n",
    "    t, fi, reverse = model\n",
    "    if reverse:\n",
    "        return features[:, fi] <= t\n",
    "    else:\n",
    "        return features[:, fi] > t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(features, labels, model):\n",
    "    # Compute the accuracy of the model\n",
    "    preds = predict(model, features)\n",
    "    return np.mean(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \n",
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def fit_model(features, labels):\n",
    "    # Initialize best_acc to impossibly low value\n",
    "    best_acc = -1.0\n",
    "\n",
    "    for fi in range(features.shape[1]):\n",
    "        # We are going to test all possible thresholds\n",
    "        thresh = features[:,fi]\n",
    "        for t in thresh:\n",
    "\n",
    "            # Get the vector for feature `fi`\n",
    "            feature_i = features[:, fi]\n",
    "            # apply threshold `t`\n",
    "            pred = (feature_i > t)\n",
    "            acc = np.mean(pred == is_virginica)\n",
    "            rev_acc = np.mean(pred == ~is_virginica)\n",
    "            if rev_acc > acc:\n",
    "                reverse = True\n",
    "                acc = rev_acc\n",
    "            else:\n",
    "                reverse = False\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_fi = fi\n",
    "                best_t = t\n",
    "                best_reverse = reverse\n",
    "        #print('Best Accuracy: ', best_acc)\n",
    "        #print('Best Feature Index: ', best_fi)\n",
    "        #print('Best Threshold: ', best_t)\n",
    "        #print('Best Reverse: ', best_reverse)\n",
    "        return best_t, best_fi, best_reverse\n",
    "    \n",
    "\n",
    "# Fit the model with features 2 and 3 for a ~94% accuracy\n",
    "model = (fit_model(features[:, 2:], labels))\n",
    "print()\n",
    "model = fit_model(features[train_data], is_virginica[train_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the for loop, all the possible thresholds for all the possible features have been tested, and the variables best_fi, best_t, and best_reverse hold our model. This is all the information we need to be able to classify a new, unknown object, that is, to assign a class to it. \n",
    "\n",
    "The following code implements exactly this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_virginica_test(fi, t, reverse, example):\n",
    "    #Apply threshold model to a new example\n",
    "    test = example[fi] > t\n",
    "    if reverse:\n",
    "        test = not test\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLOUR_FIGURE = False\n",
    "\n",
    "# Hand fixed thresholds:\n",
    "t = 1.65\n",
    "t2 = 1.75\n",
    "\n",
    "# Features to use: 3 & 2\n",
    "f0, f1 = 3, 2\n",
    "\n",
    "if COLOUR_FIGURE:\n",
    "    area1c = (1., .8, .8)\n",
    "    area2c = (.8, .8, 1.)\n",
    "else:\n",
    "    area1c = (1., 1, 1)\n",
    "    area2c = (.7, .7, .7)\n",
    "\n",
    "# Plot from 90% of smallest value to 110% of largest value\n",
    "# (all feature values are positive, otherwise this would not work very well)\n",
    "\n",
    "x0 = features[:, f0].min() * .9\n",
    "x1 = features[:, f0].max() * 1.1\n",
    "\n",
    "y0 = features[:, f1].min() * .9\n",
    "y1 = features[:, f1].max() * 1.1\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.fill_between([t, x1], [y0, y0], [y1, y1], color=area2c)\n",
    "ax.fill_between([x0, t], [y0, y0], [y1, y1], color=area1c)\n",
    "ax.plot([t, t], [y0, y1], 'k--', lw=2)\n",
    "ax.plot([t2, t2], [y0, y1], 'k:', lw=2)\n",
    "ax.scatter(features[is_virginica, f0],\n",
    "           features[is_virginica, f1], \n",
    "           c='b', \n",
    "           marker='o', \n",
    "           s=30)\n",
    "ax.scatter(features[~is_virginica, f0],\n",
    "           features[~is_virginica, f1], \n",
    "           c='r', \n",
    "           marker='x', \n",
    "           s=30)\n",
    "ax.set_ylim(y0, y1)\n",
    "ax.set_xlim(x0, x1)\n",
    "ax.set_xlabel(feature_names[f0])\n",
    "ax.set_ylabel(feature_names[f1])\n",
    "fig.tight_layout()\n",
    "fig.savefig('figure2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This machine classification is visualized above via a **decision boundary**, which tells us which features will result in one decision or another. In the above example, Iris Virginica, classified by the red cross datapoints will tend to fall in the white regions, while Iris Versicolor will tend to fall in the gray area, with a best accuracy of 94%.\n",
    "\n",
    "It also shows (as a dashed line) an alternative threshold, which will achieve exactly the same accuracy. However, we want to be able to use this model to cateogrize new instances, so we're going to need to break the dataset into training and testing data.\n",
    "\n",
    "We'll use this next example to bring in the iris data one more time and clean it up, this time removing the Setosa data since it's a low hanging fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy was 90.0%.\n",
      "Testing Accuracy was 80.0% (N = 50).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \n",
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "features = data['data'] # doing this a little differently \n",
    "labels = data['target_names'][data['target']]\n",
    "\n",
    "is_setosa = (labels == 'setosa')\n",
    "features = features[~is_setosa]\n",
    "labels = labels[~is_setosa]\n",
    "features = features[:, 2:]  # Limit features\n",
    "\n",
    "\n",
    "# Virginica vs Non-Virginica\n",
    "is_virginica = (labels == 'virginica')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "test_data = np.tile([True, False], 50)\n",
    "train_data = ~test_data\n",
    "\n",
    "model = fit_model(features[train_data], is_virginica[train_data])\n",
    "train_acc = accuracy(features[train_data], is_virginica[train_data], model)\n",
    "test_acc = accuracy(features[test_data], is_virginica[test_data], model)\n",
    "\n",
    "print('''\\\n",
    "Training Accuracy was {0:.1%}.\n",
    "Testing Accuracy was {1:.1%} (N = {2}).\n",
    "'''.format(train_acc, test_acc, test_data.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would like to use all of the data for training and all of the data for testing as well, which is impossible. We can achieve a good approximation of this impossible ideal by a method called cross-validation. One simple form of cross-validation is leave-one-out cross-validation. We will take an example out of the training data, learn a model without this example, and then test whether the model classifies this example correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \n",
      "C:\\Users\\dooki\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "for ei in range(len(features)):\n",
    "    # select all but the one at position `ei`:\n",
    "    train_data = np.ones(len(features), bool)\n",
    "    train_data[ei] = False\n",
    "    test_data = ~train_data\n",
    "    model = fit_model(features[train_data], is_virginica[train_data])\n",
    "    predictions = predict(model, features[test_data])\n",
    "    correct += np.sum(predictions == is_virginica[test_data])\n",
    "acc = correct/float(len(features))\n",
    "print('Accuracy: {0:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy on the training data, the training accuracy, is almost always an overly optimistic estimate of how well your algorithm is doing. We should always measure and report the testing accuracy, which is the accuracy on a collection of examples that were not used for training. We can get most of the benefits of leave-one-out at a fraction of the cost by using x-fold cross-validation, where x stands for a small number\n",
    "\n",
    "\n",
    "### Folds\n",
    "\n",
    "You can use any number of folds you wish. There is a trade-off between computational efficiency (the more folds, the more computation is necessary) and accurate results (the more folds, the closer you are to using the whole of the data for training). Five folds is often a good compromise. This corresponds to training with 80 percent of your data, which should already be close to what you will get from using all the data.\n",
    "\n",
    "When generating the folds, you need to be careful to keep them balanced. For example, if all of the examples in one fold come from the same class, then the results will not be representative.\n",
    "\n",
    "### Building Blocks of a Classification Model\n",
    "\n",
    "The following components are the major pieces of a any standard data classification model:\n",
    "\n",
    " - **The structure of the model**\n",
    "  - How will it make decisions?\n",
    " - **The search procedure**\n",
    "  - How do we find the model we need to use, and how do we optimize it?\n",
    " - **The gain or loss function**\n",
    "  - How do we decide which of the tested options should be returned as a solution?\n",
    "  \n",
    "## A More Complex Model\n",
    "### Seeds Dataset\n",
    "\n",
    "This dataset consists of\n",
    "measurements of wheat seeds. There are seven features that are present, which\n",
    "are as follows:\n",
    " - area A\n",
    " - perimeter P\n",
    " - compactness C = 4πA/P²\n",
    "  - compactness feature is not actually a new measurement, but a function of the previous two features, area and perimeter.\n",
    "  - This is known as **feature engineering**, and can have a big impact on performance\n",
    "  - This feature will have the same value for two kernels, one of which is twice as big as the other one, but with the same shape\n",
    "  - does not vary with size, but varies with the shape\n",
    " - length of kernel\n",
    " -  width of kernel\n",
    " - asymmetry coefficient\n",
    " - length of kernel groove\n",
    " \n",
    "There are three classes, corresponding to three wheat varieties: Canadian, Koma, and Rosa.\n",
    "\n",
    "For use with this dataset, we will introduce a new classifier: the nearest neighbor classifier. The nearest neighbor classifier is very simple. When classifying a new element, it looks at the training data for the object that is closest to it. The nearest neighbor method can be generalized to look not at a single neighbor, but to multiple ones and take a vote amongst the neighbors. This makes the method more robust to outliers or mislabeled data.\n",
    "\n",
    "We will use sciki-learn and it's prebuilt robust libraries to help with exploring this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    '''\n",
    "    data,labels = load_dataset(dataset_name)\n",
    "\n",
    "    Load a given dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : numpy ndarray\n",
    "    labels : list of str\n",
    "    '''\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open('{0}.tsv'.format(dataset_name)) as ifile:\n",
    "        for line in ifile:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            data.append([float(tk) for tk in tokens[:-1]])\n",
    "            labels.append(tokens[-1])\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the decision boundaries between these three classifications based on the classifier we just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:  88.6%\n"
     ]
    }
   ],
   "source": [
    "COLOUR_FIGURE = True\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "feature_names2 = [\n",
    "    'area',\n",
    "    'perimeter',\n",
    "    'compactness',\n",
    "    'length of kernel',\n",
    "    'width of kernel',\n",
    "    'asymmetry coefficien',\n",
    "    'length of kernel groove',\n",
    "]\n",
    "features2, labels2 = load_dataset('seeds')\n",
    "from sklearn.cross_validation import KFold\n",
    "classifier2 = KNeighborsClassifier(n_neighbors=1)  # Defaults to 5 if not specified\n",
    "\n",
    "kf = KFold(len(features2), n_folds=5, shuffle=True)\n",
    "means = []\n",
    "\n",
    "for training, testing in kf:\n",
    "    classifier2.fit(features2[training], labels2[training])\n",
    "    prediction = classifier2.predict(features2[testing])\n",
    "    \n",
    "    #fraction of correct decions per fold\n",
    "    curmean = np.mean(prediction == labels2[testing])\n",
    "    means.append(curmean)\n",
    "print('Mean Accuracy:  {:.1%}'.format(np.mean(means)))\n",
    "\n",
    "def plot_decision(features, labels, num_neighbors=1):\n",
    "    '''Plots decision boundary for KNN Classifier\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    features:  ndarray\n",
    "    labels:    sequence\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    fig:       Matplotlib Figure\n",
    "    ax :       Matplotlib Axis\n",
    "    '''\n",
    "    y0, y1 = features2[:, 2].min() * .9, features2[:, 2].max() * 1.1\n",
    "    x0, x1 = features2[:, 0].min() * .9, features2[:, 0].max() * 1.1\n",
    "    X = np.linspace(x0, x1, 1000)\n",
    "    Y = np.linspace(y0, y1, 1000)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    model = KNeighborsClassifier(num_neighbors)\n",
    "    model.fit(features2[:, (0,2)], labels2)\n",
    "    C = model.predict(np.vstack([X.ravel(), Y.ravel()]).T).reshape(X.shape)\n",
    "    if COLOUR_FIGURE:\n",
    "        cmap = ListedColormap([(1., .7, .7), (.7, 1., .7), (.7, .7, 1.)])\n",
    "    else:\n",
    "        cmap = ListedColormap([(1., 1., 1.), (.2, .2, .2), (.6, .6, .6)])\n",
    "    fig,ax = plt.subplots(figsize=(10,5))\n",
    "    ax.set_xlim(x0, x1)\n",
    "    ax.set_ylim(y0, y1)\n",
    "    ax.set_xlabel(feature_names2[0])\n",
    "    ax.set_ylabel(feature_names2[2])\n",
    "    ax.pcolormesh(X, Y, C, cmap=cmap)\n",
    "    if COLOUR_FIGURE:\n",
    "        cmap = ListedColormap([(1., .0, .0), (.1, .6, .1), (.0, .0, 1.)])\n",
    "        ax.scatter(features[:, 0], features[:, 2], c=labels, cmap=cmap)\n",
    "    else:\n",
    "        for lab, ma in zip(range(3), \"Do^\"):\n",
    "            ax.plot(features2[labels2 == lab, 0], features2[\n",
    "                     labels2 == lab, 2], ma, c=(1., 1., 1.), ms=6)\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result with prescaling: [ 0.95833333  0.92753623  0.79710145]\n"
     ]
    }
   ],
   "source": [
    "names2 = sorted(set(labels2))\n",
    "labels2 = np.array([names2.index(ell) for ell in labels2])\n",
    "\n",
    "fig, ax = plot_decision(features2, labels2)\n",
    "fig.savefig('figure3sklearn.png')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "classifier2 = Pipeline([('norm', StandardScaler()), ('knn', classifier2)])\n",
    "crossed = cross_val_score(classifier2, features2, labels2)\n",
    "print('Result with prescaling: {}'.format(crossed))\n",
    "\n",
    "features2 -= features2.mean(0)\n",
    "features2 /= features2.std(0)\n",
    "fig, ax = plot_decision(features2, labels2)\n",
    "fig.savefig('figure4sklearn.png')\n",
    "\n",
    "fig, ax = plot_decision(features2, labels2, 11)\n",
    "fig.savefig('figure5sklearn_w_11_neighbors.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure3sklearn.png\" />\n",
    "\n",
    "Figure 3\n",
    "\n",
    "\n",
    "### Preprocessing Data Normalization\n",
    "\n",
    "The Pipeline constructor takes a list of pairs (str,clf). Each pair corresponds to a step in the pipeline: the first element is a string naming the step, while the second element is the object that performs the transformation.\n",
    "\n",
    "We need to normalize all of the features to a common scale. There are many solutions to this problem; a simple one is to normalize to z-scores. The z-score of a value is how far away from the mean it is, in units of standard deviation. After normalization, every feature is in the same units (technically, every feature is now dimensionless; it has no units) and we can more confidently mix dimensions. \n",
    "\n",
    "<img src=\"figure4sklearn.png\" />\n",
    "\n",
    "Figure 4\n",
    "\n",
    "\n",
    "Prescaling brought the accuracy up to 93%. We can further refine these results by looking at the 11 nearest neighbors instead of the closest 1\n",
    "\n",
    "<img src=\"figure5sklearn_w_11_neighbors.png\" />\n",
    "\n",
    "Figure 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
